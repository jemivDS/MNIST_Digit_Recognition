{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test_x = pd.read_csv('test.csv')\n",
    "\n",
    "validate = train.iloc[32000:,:]\n",
    "train = train.iloc[:32000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Dropout, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.drop(columns=['label'])\n",
    "train_y = pd.DataFrame(train['label'])\n",
    "\n",
    "validate_x = validate.drop(columns=['label'])\n",
    "validate_y = pd.DataFrame(validate['label'])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          label\n",
       "class_id       \n",
       "0             0\n",
       "1             1\n",
       "2             2\n",
       "3             3\n",
       "4             4\n",
       "5             5\n",
       "6             6\n",
       "7             7\n",
       "8             8\n",
       "9             9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = [0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "classes = pd.DataFrame(\n",
    "    data={\n",
    "        'label': classes\n",
    "    }\n",
    ")\n",
    "\n",
    "classes.index.name = 'class_id'\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Shapes\n",
      "(32000, 784)\n",
      "(32000, 1)\n",
      "\n",
      "Validation Set Shapes\n",
      "(10000, 784)\n",
      "(10000, 1)\n",
      "\n",
      "Test Set Shape\n",
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "shape_trx = train_x.shape\n",
    "shape_try = train_y.shape\n",
    "shape_vx = validate_x.shape\n",
    "shape_vy = validate_y.shape\n",
    "shape_tex = test_x.shape\n",
    "print(\"Training Set Shapes\")\n",
    "\n",
    "print(shape_trx)\n",
    "print(shape_try)\n",
    "print(\"\\nValidation Set Shapes\")\n",
    "\n",
    "print(shape_vx)\n",
    "print(shape_vy)\n",
    "print(\"\\nTest Set Shape\")\n",
    "\n",
    "print(shape_tex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x864 with 10 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 856,
       "width": 625
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "n = classes.shape[0]\n",
    "ncols = 3\n",
    "nrows = math.ceil(n/ncols)\n",
    "\n",
    "plt.figure(figsize=[3*ncols, 3*nrows])\n",
    "for idx, cl in classes['label'].iteritems():\n",
    "    plt.subplot(nrows, ncols, idx+1)\n",
    "    \n",
    "    img = train_x.loc[train_y['label'] == idx].sample(1)\n",
    "    img = img.values.reshape(28, 28)\n",
    "    plt.imshow(img, cmap='binary')\n",
    "    \n",
    "    plt.title(classes.loc[idx, 'label'])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "class_encoder = OneHotEncoder(categories=\"auto\")\n",
    "class_encoder.fit(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_1h = class_encoder.transform(train_y).toarray()\n",
    "validate_y_1h = class_encoder.transform(validate_y).toarray()\n",
    "\n",
    "train_x_scale = (train_x.astype('float')/255).values\n",
    "test_x_scale = (test_x.astype('float')/255).values\n",
    "validate_x_scale = (validate_x.astype('float')/255).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_x_re = train_x_scale.reshape(32000,28,28,1)\n",
    "validate_x_re = validate_x_scale.reshape(10000,28,28,1)\n",
    "test_x_re = test_x_scale.reshape(28000,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp: HyperParameters):\n",
    "    \n",
    "    # Adding hyperparameters\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    convol_1 = hp.Int(name = 'convolutional layer 1', min_value=20, max_value=120, step=20) \n",
    "    convol_2 = hp.Int(name = 'convolutional layer 2', min_value=10, max_value=60, step=10) \n",
    "    \n",
    "    kernel_size = hp.Int(name = 'kernel_size', min_value=1, max_value=4, step=1)\n",
    "\n",
    "    dense_units = hp.Int(name = 'dense units', min_value=40, max_value=160, step=20) \n",
    "    dense_act = hp.Choice(name = 'dense activation', values = ['relu','sigmoid'])\n",
    "\n",
    "    dropout = hp.Float(name = 'dropout', min_value=0.05, max_value=0.4, step=0.05)\n",
    "\n",
    "    opt_lr = hp.Float(name='learning_rate', min_value=1e-3, max_value=5e-3, step=5e-4)\n",
    "    \n",
    "    max_pooling = hp.Int(name = 'max pooling', min_value=2, max_value=3, step=1)\n",
    "\n",
    "    \n",
    "    # Creating layers\n",
    "    \n",
    "    model.add(Conv2D(convol_1, kernel_size=(kernel_size,kernel_size), input_shape=(28,28,1))),\n",
    "        \n",
    "    model.add(MaxPooling2D(pool_size=(max_pooling, max_pooling))),\n",
    "\n",
    "    model.add(Conv2D(convol_2, kernel_size=(kernel_size,kernel_size), input_shape=((28 + 1 - kernel_size) + 1 - max_pooling,\n",
    "                    (28 + 1 - kernel_size) + 1 - max_pooling, convol_1))),\n",
    "        \n",
    "    model.add(MaxPooling2D(pool_size=(max_pooling, max_pooling))),\n",
    "\n",
    "    model.add(Flatten()),\n",
    "        \n",
    "    model.add(Dense(units=dense_units, activation=dense_act)),        \n",
    "        \n",
    "    model.add(Dropout(dropout)),\n",
    "    \n",
    "\n",
    "    model.add(Dense(units = 10,activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "  \n",
    "    model.compile(optimizers.Adam(lr=opt_lr), \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, epochs):\n",
    "    history = model.fit(\n",
    "        x=train_x_re, \n",
    "        y=train_y_1h, \n",
    "\n",
    "        epochs=epochs,\n",
    "\n",
    "        batch_size=128,\n",
    "        shuffle=True,\n",
    "        validation_data=(validate_x_re, validate_y_1h)\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 8\n",
      "convolutional layer 1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 20, 'max_value': 120, 'step': 20, 'sampling': None}\n",
      "convolutional layer 2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 10, 'max_value': 60, 'step': 10, 'sampling': None}\n",
      "kernel_size (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 4, 'step': 1, 'sampling': None}\n",
      "dense units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 40, 'max_value': 160, 'step': 20, 'sampling': None}\n",
      "dense activation (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'sigmoid'], 'ordered': False}\n",
      "dropout (Float)\n",
      "{'default': 0.05, 'conditions': [], 'min_value': 0.05, 'max_value': 0.4, 'step': 0.05, 'sampling': None}\n",
      "learning_rate (Float)\n",
      "{'default': 0.001, 'conditions': [], 'min_value': 0.001, 'max_value': 0.005, 'step': 0.0005, 'sampling': None}\n",
      "max pooling (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 3, 'step': 1, 'sampling': None}\n"
     ]
    }
   ],
   "source": [
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=2,\n",
    "    directory='clothing_estimator',\n",
    "    \n",
    "    # Experiment name must change if you modify\n",
    "    # the model structure or the set of hyperparameters.\n",
    "    project_name='clothing_estimator_'\n",
    ")\n",
    "\n",
    "# This displays which hyperparameters are tunable, and their respective distribution.\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 02m 09s]\n",
      "val_accuracy: 0.9664500057697296\n",
      "\n",
      "Best val_accuracy So Far: 0.9831999838352203\n",
      "Total elapsed time: 00h 17m 32s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "tuner.search(    \n",
    "    # All parameters here are passed thru to Model.fit function.\n",
    "    x=train_x_re, \n",
    "    y=train_y_1h, \n",
    "    validation_data=(validate_x_re, validate_y_1h),\n",
    "    \n",
    "    # It's a good idea to have low number of epochs,\n",
    "    # to test the learning process, but not for the final model training.\n",
    "    epochs=5,\n",
    "    batch_size=250,\n",
    "    shuffle=True\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>convolutional layer 1</th>\n",
       "      <th>convolutional layer 2</th>\n",
       "      <th>kernel_size</th>\n",
       "      <th>dense units</th>\n",
       "      <th>dense activation</th>\n",
       "      <th>dropout</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max pooling</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>290171e28ef3d13823c4d40978f3f364</th>\n",
       "      <td>0.98320</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f92454707feb4828c5b4f1bc60bfb2fe</th>\n",
       "      <td>0.97335</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3961e0d29f95f8f246e7e449996a02f4</th>\n",
       "      <td>0.97060</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322a483b379c64795543b01962c2dff7</th>\n",
       "      <td>0.96645</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46c3f711b76529e6ff07460cf9c7bb78</th>\n",
       "      <td>0.90630</td>\n",
       "      <td>100</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    score  convolutional layer 1  \\\n",
       "trial_id                                                           \n",
       "290171e28ef3d13823c4d40978f3f364  0.98320                     80   \n",
       "f92454707feb4828c5b4f1bc60bfb2fe  0.97335                    100   \n",
       "3961e0d29f95f8f246e7e449996a02f4  0.97060                    100   \n",
       "322a483b379c64795543b01962c2dff7  0.96645                     60   \n",
       "46c3f711b76529e6ff07460cf9c7bb78  0.90630                    100   \n",
       "\n",
       "                                  convolutional layer 2  kernel_size  \\\n",
       "trial_id                                                               \n",
       "290171e28ef3d13823c4d40978f3f364                     60            2   \n",
       "f92454707feb4828c5b4f1bc60bfb2fe                     20            4   \n",
       "3961e0d29f95f8f246e7e449996a02f4                     40            2   \n",
       "322a483b379c64795543b01962c2dff7                     10            3   \n",
       "46c3f711b76529e6ff07460cf9c7bb78                     50            1   \n",
       "\n",
       "                                  dense units dense activation  dropout  \\\n",
       "trial_id                                                                  \n",
       "290171e28ef3d13823c4d40978f3f364          100          sigmoid     0.15   \n",
       "f92454707feb4828c5b4f1bc60bfb2fe           40             relu     0.15   \n",
       "3961e0d29f95f8f246e7e449996a02f4          120             relu     0.15   \n",
       "322a483b379c64795543b01962c2dff7          100          sigmoid     0.05   \n",
       "46c3f711b76529e6ff07460cf9c7bb78           40          sigmoid     0.10   \n",
       "\n",
       "                                  learning_rate  max pooling  \n",
       "trial_id                                                      \n",
       "290171e28ef3d13823c4d40978f3f364         0.0025            2  \n",
       "f92454707feb4828c5b4f1bc60bfb2fe         0.0050            3  \n",
       "3961e0d29f95f8f246e7e449996a02f4         0.0020            3  \n",
       "322a483b379c64795543b01962c2dff7         0.0020            3  \n",
       "46c3f711b76529e6ff07460cf9c7bb78         0.0015            2  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([\n",
    "    {\n",
    "        'trial_id': t.trial_id,\n",
    "        'score': t.score,\n",
    "        **t.hyperparameters.values \n",
    "    }\n",
    "    for t in tuner.oracle.get_best_trials(num_trials=5)\n",
    "]).set_index('trial_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "250/250 [==============================] - 26s 104ms/step - loss: 0.3461 - accuracy: 0.8997 - val_loss: 0.1092 - val_accuracy: 0.9701\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 25s 100ms/step - loss: 0.0987 - accuracy: 0.9726 - val_loss: 0.0703 - val_accuracy: 0.9788\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 24s 98ms/step - loss: 0.0682 - accuracy: 0.9810 - val_loss: 0.0503 - val_accuracy: 0.9844\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 25s 102ms/step - loss: 0.0472 - accuracy: 0.9867 - val_loss: 0.0508 - val_accuracy: 0.9845\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 26s 103ms/step - loss: 0.0379 - accuracy: 0.9890 - val_loss: 0.0459 - val_accuracy: 0.9850\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 24s 98ms/step - loss: 0.0303 - accuracy: 0.9916 - val_loss: 0.0482 - val_accuracy: 0.9853\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 25s 102ms/step - loss: 0.0275 - accuracy: 0.9921 - val_loss: 0.0467 - val_accuracy: 0.9854\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 25s 98ms/step - loss: 0.0239 - accuracy: 0.9932 - val_loss: 0.0453 - val_accuracy: 0.9848\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 26s 102ms/step - loss: 0.0206 - accuracy: 0.9937 - val_loss: 0.0445 - val_accuracy: 0.9864\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 28s 112ms/step - loss: 0.0156 - accuracy: 0.9962 - val_loss: 0.0523 - val_accuracy: 0.9842\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 28s 111ms/step - loss: 0.0153 - accuracy: 0.9957 - val_loss: 0.0446 - val_accuracy: 0.9865\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 26s 104ms/step - loss: 0.0139 - accuracy: 0.9960 - val_loss: 0.0464 - val_accuracy: 0.9859\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 25s 100ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.0472 - val_accuracy: 0.9855\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 28s 113ms/step - loss: 0.0140 - accuracy: 0.9956 - val_loss: 0.0495 - val_accuracy: 0.9846\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 25s 100ms/step - loss: 0.0133 - accuracy: 0.9958 - val_loss: 0.0490 - val_accuracy: 0.9852\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 25s 99ms/step - loss: 0.0130 - accuracy: 0.9966 - val_loss: 0.0514 - val_accuracy: 0.9853\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 23s 92ms/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 0.0484 - val_accuracy: 0.9855\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 23s 90ms/step - loss: 0.0140 - accuracy: 0.9958 - val_loss: 0.0471 - val_accuracy: 0.9855\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 27s 109ms/step - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.0589 - val_accuracy: 0.9839\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 31s 124ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.0476 - val_accuracy: 0.9862\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 23s 94ms/step - loss: 0.0137 - accuracy: 0.9958 - val_loss: 0.0474 - val_accuracy: 0.9864\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 24s 94ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.0503 - val_accuracy: 0.9856\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 26s 103ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.0488 - val_accuracy: 0.9859\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 33s 133ms/step - loss: 0.0086 - accuracy: 0.9974 - val_loss: 0.0460 - val_accuracy: 0.9872\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.0087 - accuracy: 0.9974 - val_loss: 0.0474 - val_accuracy: 0.9871\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 0.0546 - val_accuracy: 0.9854\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 26s 105ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.0549 - val_accuracy: 0.9852\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.0174 - accuracy: 0.9938 - val_loss: 0.0503 - val_accuracy: 0.9861\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 25s 102ms/step - loss: 0.0143 - accuracy: 0.9950 - val_loss: 0.0540 - val_accuracy: 0.9844\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 25s 102ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.0517 - val_accuracy: 0.9862\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 25s 102ms/step - loss: 0.0075 - accuracy: 0.9976 - val_loss: 0.0520 - val_accuracy: 0.9867\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 28s 111ms/step - loss: 0.0087 - accuracy: 0.9974 - val_loss: 0.0525 - val_accuracy: 0.9859\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 28s 114ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.0562 - val_accuracy: 0.9873\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 28s 111ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.0641 - val_accuracy: 0.9851\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 26s 105ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.0519 - val_accuracy: 0.9880\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 25s 102ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.0559 - val_accuracy: 0.9863\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 26s 104ms/step - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.0576 - val_accuracy: 0.9850\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 25s 100ms/step - loss: 0.0138 - accuracy: 0.9955 - val_loss: 0.0586 - val_accuracy: 0.9857\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 26s 103ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.0518 - val_accuracy: 0.9870\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 26s 105ms/step - loss: 0.0116 - accuracy: 0.9959 - val_loss: 0.0595 - val_accuracy: 0.9859\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 26s 103ms/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 0.0532 - val_accuracy: 0.9858\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 26s 103ms/step - loss: 0.0107 - accuracy: 0.9961 - val_loss: 0.0547 - val_accuracy: 0.9866\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 26s 104ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.0589 - val_accuracy: 0.9856\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.0108 - accuracy: 0.9962 - val_loss: 0.0696 - val_accuracy: 0.9835\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 26s 103ms/step - loss: 0.0118 - accuracy: 0.9962 - val_loss: 0.0575 - val_accuracy: 0.9860\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.0603 - val_accuracy: 0.9850\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 26s 103ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.0531 - val_accuracy: 0.9869\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 25s 100ms/step - loss: 0.0112 - accuracy: 0.9958 - val_loss: 0.0605 - val_accuracy: 0.9851\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 0.0526 - val_accuracy: 0.9868\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 26s 104ms/step - loss: 0.0108 - accuracy: 0.9959 - val_loss: 0.0573 - val_accuracy: 0.9861\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.0133 - accuracy: 0.9954 - val_loss: 0.0530 - val_accuracy: 0.9861\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 26s 104ms/step - loss: 0.0107 - accuracy: 0.9962 - val_loss: 0.0536 - val_accuracy: 0.9872\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.0127 - accuracy: 0.9955 - val_loss: 0.0539 - val_accuracy: 0.9867\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.0590 - val_accuracy: 0.9863\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 26s 105ms/step - loss: 0.0108 - accuracy: 0.9962 - val_loss: 0.0663 - val_accuracy: 0.9850\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.0140 - accuracy: 0.9952 - val_loss: 0.0592 - val_accuracy: 0.9858\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 26s 103ms/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 0.0589 - val_accuracy: 0.9855\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.0597 - val_accuracy: 0.9865\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.0598 - val_accuracy: 0.9870\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 26s 106ms/step - loss: 0.0138 - accuracy: 0.9952 - val_loss: 0.0561 - val_accuracy: 0.9868\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.0133 - accuracy: 0.9952 - val_loss: 0.0613 - val_accuracy: 0.9859\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 26s 103ms/step - loss: 0.0126 - accuracy: 0.9954 - val_loss: 0.0619 - val_accuracy: 0.9870\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 26s 103ms/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.0571 - val_accuracy: 0.9864\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 25s 102ms/step - loss: 0.0115 - accuracy: 0.9959 - val_loss: 0.0718 - val_accuracy: 0.9832\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 26s 104ms/step - loss: 0.0119 - accuracy: 0.9957 - val_loss: 0.0677 - val_accuracy: 0.9860\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.0137 - accuracy: 0.9952 - val_loss: 0.0600 - val_accuracy: 0.9853\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.0118 - accuracy: 0.9959 - val_loss: 0.0654 - val_accuracy: 0.9851\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 27s 106ms/step - loss: 0.0108 - accuracy: 0.9962 - val_loss: 0.0633 - val_accuracy: 0.9865\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 26s 104ms/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 0.0606 - val_accuracy: 0.9860\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 27s 108ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 0.0638 - val_accuracy: 0.9852\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.0584 - val_accuracy: 0.9864\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 27s 109ms/step - loss: 0.0140 - accuracy: 0.9949 - val_loss: 0.0672 - val_accuracy: 0.9838\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 26s 104ms/step - loss: 0.0110 - accuracy: 0.9960 - val_loss: 0.0591 - val_accuracy: 0.9859\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 26s 103ms/step - loss: 0.0122 - accuracy: 0.9959 - val_loss: 0.0621 - val_accuracy: 0.9855\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 26s 104ms/step - loss: 0.0120 - accuracy: 0.9963 - val_loss: 0.0572 - val_accuracy: 0.9863\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.0592 - val_accuracy: 0.9857\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.0093 - accuracy: 0.9966 - val_loss: 0.0568 - val_accuracy: 0.9870\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 26s 104ms/step - loss: 0.0104 - accuracy: 0.9970 - val_loss: 0.0622 - val_accuracy: 0.9863\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 25s 102ms/step - loss: 0.0111 - accuracy: 0.9964 - val_loss: 0.0584 - val_accuracy: 0.9863\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 26s 104ms/step - loss: 0.0116 - accuracy: 0.9962 - val_loss: 0.0596 - val_accuracy: 0.9869\n",
      "Epoch 81/100\n",
      "250/250 [==============================] - 25s 102ms/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.0560 - val_accuracy: 0.9868\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 26s 104ms/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.0611 - val_accuracy: 0.9855\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 27s 106ms/step - loss: 0.0135 - accuracy: 0.9955 - val_loss: 0.0637 - val_accuracy: 0.9850\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 25s 102ms/step - loss: 0.0118 - accuracy: 0.9958 - val_loss: 0.0581 - val_accuracy: 0.9852\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 26s 104ms/step - loss: 0.0154 - accuracy: 0.9948 - val_loss: 0.0607 - val_accuracy: 0.9862\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 26s 105ms/step - loss: 0.0132 - accuracy: 0.9955 - val_loss: 0.0554 - val_accuracy: 0.9868\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 25s 102ms/step - loss: 0.0139 - accuracy: 0.9949 - val_loss: 0.0701 - val_accuracy: 0.9842\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 27s 106ms/step - loss: 0.0141 - accuracy: 0.9949 - val_loss: 0.0638 - val_accuracy: 0.9843\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 25s 102ms/step - loss: 0.0118 - accuracy: 0.9957 - val_loss: 0.0644 - val_accuracy: 0.9847\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 27s 109ms/step - loss: 0.0107 - accuracy: 0.9963 - val_loss: 0.0642 - val_accuracy: 0.9850\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.0118 - accuracy: 0.9954 - val_loss: 0.0630 - val_accuracy: 0.9853\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 25s 102ms/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 0.0678 - val_accuracy: 0.9824\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 26s 105ms/step - loss: 0.0145 - accuracy: 0.9950 - val_loss: 0.0733 - val_accuracy: 0.9830\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.0131 - accuracy: 0.9951 - val_loss: 0.0641 - val_accuracy: 0.9848\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 46s 183ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.0712 - val_accuracy: 0.9841\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 32s 127ms/step - loss: 0.0125 - accuracy: 0.9961 - val_loss: 0.0671 - val_accuracy: 0.9848\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 27s 106ms/step - loss: 0.0140 - accuracy: 0.9952 - val_loss: 0.0588 - val_accuracy: 0.9864\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 26s 103ms/step - loss: 0.0143 - accuracy: 0.9952 - val_loss: 0.0570 - val_accuracy: 0.9866\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 26s 102ms/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 0.0679 - val_accuracy: 0.9857\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 26s 106ms/step - loss: 0.0100 - accuracy: 0.9964 - val_loss: 0.0635 - val_accuracy: 0.9854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd05e6a7f40>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "best_hyperparameters.values\n",
    "\n",
    "classifier = build_model(best_hyperparameters)\n",
    "train_model(classifier, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y_pred = classifier.predict(test_x_re)\n",
    "test_y_pred_binary = class_encoder.transform(np.argmax(test_y_pred,1).reshape(-1,1)).toarray()\n",
    "test_y_pred_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_pred_binary = pd.DataFrame(test_y_pred_binary)\n",
    "test_y_pred_binary_label = test_y_pred_binary.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(test_y_pred_binary_label).reset_index()\n",
    "df.rename(columns={'index':'ImageId', 0:'Label'}, inplace=True)\n",
    "\n",
    "df['ImageId'] = df['ImageId']+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('numbers.txt', header=True, index=None, sep=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
